{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf6698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation and data handling\n",
    "import numpy as ny #numeric operations array,maths\n",
    "from sqlalchemy import create_engine , text #build database conn and sql exection\n",
    "import random #random offset data\n",
    "from sqlalchemy.types import String,INTEGER,Numeric #define columns types when writing to sql   \n",
    "import time \n",
    "import matplotlib as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be2de9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine (\"postgresql://postgres:123456@localhost:5432/project1\") #initialize engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d3d9043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sampling 200,000 rows from silver1.cleaned ...\n",
      "âœ… Sample fetched: 200,000 rows\n",
      "\n",
      "ðŸ”¹ Writing sampled rows to gold1.presentation ...\n",
      "âœ… Written to gold1.presentation: 200,000 rows\n",
      "\n",
      "ðŸ”¹ Total time taken in writing data: 5.06 Minutes\n"
     ]
    }
   ],
   "source": [
    "yes = 1\n",
    "SAMPLE_SIZE = 200000\n",
    "SILVER_SCHEMA = 'silver1'\n",
    "SILVER_TABLE = 'cleaned'\n",
    "GOLD_SCHEMA = 'gold1'\n",
    "GOLD_TABLE = 'presentation'\n",
    "\n",
    "Gold_Columns = [\n",
    "     'state','survey_month','survey_date','month','day','year',\n",
    "    'disposition_code','sequence_number','primary_sampling_unit',\n",
    "    'telephone_number','private_residence','state_residence','cell_phone',\n",
    "    'num_of_adults','num_of_men','num_of_women',\n",
    "    'general_health','physical_health_days','mental_health_days','poor_health_days',\n",
    "    'has_health_plan','has_personal_doctor','medical_cost_issue','last_checkup',\n",
    "    'high_blood_pressure','high_cholesterol','cholesterol_check','diagnosed_diabetes',\n",
    "    'had_heart_attack','had_coronary_heart_disease','had_stroke','has_asthma',\n",
    "    'had_skin_cancer','had_other_cancer','has_copd','has_arthritis',\n",
    "    'has_depression','had_kidney_disease'\n",
    "]\n",
    "\n",
    "\n",
    "disease = [\n",
    "    'high_blood_pressure', 'high_cholesterol', 'cholesterol_check', 'diagnosed_diabetes',\n",
    "    'had_heart_attack', 'had_coronary_heart_disease', 'had_stroke', 'has_asthma',\n",
    "    'had_skin_cancer', 'had_other_cancer', 'has_copd', 'has_arthritis', 'has_depression', 'had_kidney_disease'\n",
    "]\n",
    "\n",
    "#Database Connect\n",
    "def get_engine (uri : str ) : \n",
    "    return create_engine(uri)\n",
    "\n",
    "def table_rowcount(engine , schema : str , table : str ) -> int : #define a func and take para engine , schema and table which is str data type and int hints that this func return int\n",
    "    with engine.connect() as conn: #create a conn to the database and make executable to run sql query\n",
    "        return conn.exec_driver_sql(f\"SELECT COUNT(*) FROM {schema}.{table};\").scalar() #exec query using sqlalchemy and scalar extracts a single value\n",
    "\n",
    "def ensure_schemas(engine):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {SILVER_SCHEMA};\"))\n",
    "        conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {GOLD_SCHEMA};\"))\n",
    "\n",
    "\n",
    "def get_table_columns(engine, schema: str, table: str):  #define a func and take para engine , schema and table which is str data type and int hints that this func return int\n",
    "    df = pd.read_sql_query(text(f\"SELECT * FROM {schema}.{table} LIMIT 1\"), con=engine) #create a dataframe in which retrieve column name \n",
    "    return df.columns.tolist() #df has columns name and to list make a list of column names\n",
    "\n",
    "def fetch_random_sample(engine , sample_size = SAMPLE_SIZE ) -> pd.DataFrame : #def a func with par engine and sample size  and type hint that this fun return a pandas dataframe \n",
    "    total_df = pd.read_sql_query(\n",
    "        sql=text(f\"SELECT COUNT(*) AS c FROM {SILVER_SCHEMA}.{SILVER_TABLE}\"),\n",
    "        con=engine\n",
    "    ) #count total num of rows\n",
    "    \n",
    "    total = int(total_df['c'][0]) #total rows\n",
    "    if total == 0:\n",
    "        raise RuntimeError(f\"{SILVER_SCHEMA}.{SILVER_TABLE} is empty.\")\n",
    "    \n",
    "    offset = max(0,random.randint(0,max(0,total - sample_size)))  # We want to avoid asking for rows that donâ€™t exist. Maximum offset = total rows âˆ’ sample size = 10 âˆ’ 4 = 6\n",
    "    #So OFFSET can only be 0,1,2,3,4,5,6 If OFFSET = 6 and LIMIT = 4 â†’ take rows 7,8,9,10 max prevent negative numbers and if neg return 0\n",
    "\n",
    "    # this query return gold columns offset to limit sample size\n",
    "    query = f\"\"\"\n",
    "        SELECT {', '.join(Gold_Columns)}\n",
    "        FROM {SILVER_SCHEMA}.{SILVER_TABLE}\n",
    "        OFFSET {offset}\n",
    "        LIMIT {sample_size}\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql=text(query), con =engine) #exec the sql query and reads data to pandas dataframe\n",
    "    df = enrich_gold_layer(df)\n",
    "    return df\n",
    "\n",
    "def enrich_gold_layer(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    total = (df[disease] == yes).sum(axis=1)\n",
    "    df['total_disease'] = total.astype('int')\n",
    "    df['has_any_disease'] = (df['total_disease'] > 0).astype('int8')\n",
    "    df['multimorbidity_flag'] = (df['total_disease'] >= 2 ).astype('int') \n",
    "    df['severe_multimorbidity_flag'] = (df['total_disease'] >= 3 ).astype('int') \n",
    "    return df\n",
    "\n",
    "def write_sample_to_gold(engine, df: pd.DataFrame) -> int:\n",
    "    # Ensure column order & presence\n",
    "    existing = [c for c in Gold_Columns if c in df.columns] #Loop through every column c in Gold_Columns Keep it only if it exists in the DataFrame.\n",
    "    # Include the new columns too when writing\n",
    "    extra_cols = ['total_disease','has_any_disease','multimorbidity_flag',\n",
    "                  'severe_multimorbidity_flag']\n",
    "    for c in extra_cols: # will raise an error if any column doesnt exist\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"Missing expected enriched column: {c}\")\n",
    "\n",
    "    df = df[existing + extra_cols]\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        df.to_sql(\n",
    "            name=GOLD_TABLE,\n",
    "            con=conn,\n",
    "            schema=GOLD_SCHEMA,\n",
    "            if_exists='replace',  \n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=50_000\n",
    "        )\n",
    "    return len(df)\n",
    "\n",
    "\n",
    "def run_gold_pipeline(engine):\n",
    "    start_time = time.perf_counter()   \n",
    "\n",
    "    try:\n",
    "        ensure_schemas(engine)\n",
    "\n",
    "        print(\"\\nðŸ”¹ Sampling 200,000 rows from silver1.cleaned ...\")\n",
    "        df = fetch_random_sample(engine, SAMPLE_SIZE)\n",
    "        print(f\"âœ… Sample fetched: {len(df):,} rows\")\n",
    "\n",
    "        if df.empty:\n",
    "            raise RuntimeError(\"Sample is empty\")\n",
    "\n",
    "        print(\"\\nðŸ”¹ Writing sampled rows to gold1.presentation ...\")\n",
    "        written = write_sample_to_gold(engine, df)\n",
    "        print(f\"âœ… Written to gold1.presentation: {written:,} rows\")\n",
    "\n",
    "        end_time = time.perf_counter()  \n",
    "        elaspsed_sec = end_time - start_time\n",
    "        elaspsed_min = elaspsed_sec / 60 \n",
    "        print(f\"\\nðŸ”¹ Total time taken in writing data: {elaspsed_min:.2f} Minutes\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\" ERROR in pipeline:\", e)\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ENGINE_URI = \"postgresql+psycopg2://postgres:123456@localhost:5432/Project1\"\n",
    "    engine = get_engine(ENGINE_URI)\n",
    "    run_gold_pipeline(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b4133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
