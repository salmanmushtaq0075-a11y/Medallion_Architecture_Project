{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bca34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fc8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dae92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://postgres:123456@localhost:5432/Project1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00528b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM gold1.presentation\", engine)\n",
    "\n",
    "DISEASE_FLAGS = [\n",
    "    'high_blood_pressure','high_cholesterol','diagnosed_diabetes',\n",
    "    'had_heart_attack','had_coronary_heart_disease','had_stroke',\n",
    "    'has_asthma','had_skin_cancer','had_other_cancer','has_copd',\n",
    "    'has_arthritis','has_depression','had_kidney_disease'\n",
    "]\n",
    "\n",
    "def build_burden_kpis(df):\n",
    "    for c in DISEASE_FLAGS + ['state']:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df['disease_count'] = (df[DISEASE_FLAGS] == 1).sum(axis=1)\n",
    "    df['has_any_disease'] = (df['disease_count'] > 0).astype('int8')\n",
    "\n",
    "    sgrp = df.groupby('state')\n",
    "    \n",
    "    out = (pd.DataFrame({\n",
    "        'respondents': sgrp.size(),\n",
    "        'total_diseases': sgrp['disease_count'].sum(),\n",
    "        'avg_disease_count': sgrp['disease_count'].mean(),\n",
    "        'prevalence_any_disease': (sgrp['has_any_disease'].sum() / sgrp.size())\n",
    "    }).reset_index())\n",
    "\n",
    "    # ‚úÖ Round for readability\n",
    "    out['avg_disease_count'] = out['avg_disease_count'].round(2)\n",
    "    out['prevalence_any_disease'] = out['prevalence_any_disease'].round(2)\n",
    "    return out\n",
    "\n",
    "burden_state = build_burden_kpis(df)\n",
    "\n",
    "burden_state.to_sql(\n",
    "    \"metrics_burden_by_state\",\n",
    "    engine,\n",
    "    schema=\"gold1\",\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    method=\"multi\",\n",
    "    chunksize=50_000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748cab6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def build_condition_counts_by_state(df, flags):\n",
    "    for c in flags + ['state']:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    out = (df.groupby('state')[(flags)]\n",
    "             .apply(lambda g: (g == 1).sum())\n",
    "             .reset_index())\n",
    "    out = out.rename(columns={c: f\"{c}_cases\" for c in flags})\n",
    "    return out\n",
    "\n",
    "cond_state = build_condition_counts_by_state(df, DISEASE_FLAGS)\n",
    "cond_state.to_sql(\"condition_counts_by_state\", engine, schema=\"gold1\", if_exists=\"replace\", index=False, method=\"multi\", chunksize=50_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580495c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DAY_METRICS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      7\u001b[39m     out = pd.DataFrame({\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpct_no_health_plan\u001b[39m\u001b[33m'\u001b[39m: (\u001b[32m1\u001b[39m - (g[\u001b[33m'\u001b[39m\u001b[33mhas_health_plan\u001b[39m\u001b[33m'\u001b[39m].mean())),\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpct_no_doctor\u001b[39m\u001b[33m'\u001b[39m:     (\u001b[32m1\u001b[39m - (g[\u001b[33m'\u001b[39m\u001b[33mhas_personal_doctor\u001b[39m\u001b[33m'\u001b[39m].mean())),\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_poor_health_days\u001b[39m\u001b[33m'\u001b[39m: g[\u001b[33m'\u001b[39m\u001b[33mpoor_health_days\u001b[39m\u001b[33m'\u001b[39m].mean(),\n\u001b[32m     11\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_disease_count\u001b[39m\u001b[33m'\u001b[39m: g[\u001b[33m'\u001b[39m\u001b[33mdisease_count\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m     12\u001b[39m     }).reset_index()\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m access_burden = \u001b[43maccess_vs_burden_by_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m access_burden.to_sql(\u001b[33m\"\u001b[39m\u001b[33maccess_vs_burden_state\u001b[39m\u001b[33m\"\u001b[39m, engine, schema=\u001b[33m\"\u001b[39m\u001b[33mgold1\u001b[39m\u001b[33m\"\u001b[39m, if_exists=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m, method=\u001b[33m'\u001b[39m\u001b[33mmulti\u001b[39m\u001b[33m'\u001b[39m, chunksize=\u001b[32m50_000\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36maccess_vs_burden_by_state\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccess_vs_burden_by_state\u001b[39m(df):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mhas_health_plan\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mhas_personal_doctor\u001b[39m\u001b[33m'\u001b[39m] + \u001b[43mDAY_METRICS\u001b[49m + DISEASE_FLAGS + [\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      3\u001b[39m         df[c] = pd.to_numeric(df[c], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mdisease_count\u001b[39m\u001b[33m'\u001b[39m] = (df[DISEASE_FLAGS] == \u001b[32m1\u001b[39m).sum(axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'DAY_METRICS' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def access_vs_burden_by_state(df):\n",
    "    for c in ['has_health_plan','has_personal_doctor'] + DAY_METRICS + DISEASE_FLAGS + ['state']:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df['disease_count'] = (df[DISEASE_FLAGS] == 1).sum(axis=1)\n",
    "\n",
    "    g = df.groupby('state')\n",
    "    out = pd.DataFrame({\n",
    "        'pct_no_health_plan': (1 - (g['has_health_plan'].mean())),\n",
    "        'pct_no_doctor':     (1 - (g['has_personal_doctor'].mean())),\n",
    "        'avg_poor_health_days': g['poor_health_days'].mean(),\n",
    "        'avg_disease_count': g['disease_count'].mean()\n",
    "    }).reset_index()\n",
    "    return out\n",
    "\n",
    "access_burden = access_vs_burden_by_state(df)\n",
    "access_burden.to_sql(\"access_vs_burden_state\", engine, schema=\"gold1\", if_exists=\"replace\", index=False, method='multi', chunksize=50_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ade56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL version: PostgreSQL 18.1 on x86_64-windows, compiled by msvc-19.44.35219, 64-bit\n",
      "Silver table rowcount: 2,000,000\n",
      "\n",
      "üîπ Sampling 200,000 rows from silver1.cleaned ...\n",
      "‚úÖ Sample fetched: 200,000 rows\n",
      "\n",
      "üîπ Writing sampled rows to gold1.presentation ...\n",
      "‚úÖ Written to gold1.presentation: 200,000 rows\n",
      "\n",
      "üîπ Building analytics (null profiles, prevalence, averages) ...\n",
      "‚úÖ State metrics rows: 52 | State-month metrics rows: 229\n",
      "\n",
      "üîπ Writing aggregated outputs to Gold tables ...\n",
      "‚úÖ Gold layer analytics written and indexed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Gold (Presentation) Layer Pipeline\n",
    "----------------------------------\n",
    "- Samples 200,000 rows from silver1.cleaned\n",
    "- Enriches sample with basic disease burden columns\n",
    "- Writes sample to gold1.presentation\n",
    "- Aggregates state & state+month metrics (rounded to 2 dp)\n",
    "- Writes to gold1.metrics_by_state and gold1.metrics_by_state_month (NUMERIC(10,2))\n",
    "- Creates indexes and logs diagnostics\n",
    "\n",
    "Requirements:\n",
    "  pip install pandas numpy sqlalchemy psycopg2-binary\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.types import Integer, Numeric, String\n",
    "\n",
    "# ---------------------\n",
    "# CONFIG\n",
    "# ---------------------\n",
    "SILVER_SCHEMA = 'silver1'\n",
    "SILVER_TABLE  = 'cleaned'\n",
    "\n",
    "GOLD_SCHEMA   = 'gold1'\n",
    "GOLD_TABLE    = 'presentation'           # sample landing table\n",
    "GOLD_AGG_STATE        = 'metrics_by_state'\n",
    "GOLD_AGG_STATE_MONTH  = 'metrics_by_state_month'\n",
    "\n",
    "SAMPLE_SIZE = 200000  # 2 lakh\n",
    "YES_VALUE   = 1        # assumed \"Yes\" code\n",
    "\n",
    "# Columns available in gold presentation table (as per your Silver)\n",
    "GOLD_COLS = [\n",
    "    'state','survey_month','survey_date','month','day','year',\n",
    "    'disposition_code','sequence_number','primary_sampling_unit',\n",
    "    'telephone_number','private_residence','state_residence','cell_phone',\n",
    "    'num_of_adults','num_of_men','num_of_women',\n",
    "    'general_health','physical_health_days','mental_health_days','poor_health_days',\n",
    "    'has_health_plan','has_personal_doctor','medical_cost_issue','last_checkup',\n",
    "    'high_blood_pressure','high_cholesterol','cholesterol_check','diagnosed_diabetes',\n",
    "    'had_heart_attack','had_coronary_heart_disease','had_stroke','has_asthma',\n",
    "    'had_skin_cancer','had_other_cancer','has_copd','has_arthritis',\n",
    "    'has_depression','had_kidney_disease'\n",
    "]\n",
    "\n",
    "# Indicator columns (treated as binary: YES_VALUE means positive)\n",
    "INDICATORS = [\n",
    "    'has_health_plan','has_personal_doctor','medical_cost_issue',\n",
    "    'high_blood_pressure','high_cholesterol','cholesterol_check','diagnosed_diabetes',\n",
    "    'had_heart_attack','had_coronary_heart_disease','had_stroke','has_asthma',\n",
    "    'had_skin_cancer','had_other_cancer','has_copd','has_arthritis',\n",
    "    'has_depression','had_kidney_disease'\n",
    "]\n",
    "\n",
    "DAY_METRICS = ['physical_health_days','mental_health_days','poor_health_days']\n",
    "\n",
    "# Programmatic target column sets for Gold aggregate tables\n",
    "STATE_AGG_COLS = (\n",
    "    ['state', 'rows'] +\n",
    "    [f'{c}_prev' for c in INDICATORS] +\n",
    "    [f'{c}_avg' for c in DAY_METRICS] +\n",
    "    [f'{c}_null_pct' for c in INDICATORS + DAY_METRICS]\n",
    ")\n",
    "STATE_MONTH_AGG_COLS = (\n",
    "    ['state', 'month', 'rows'] +\n",
    "    [f'{c}_prev' for c in INDICATORS] +\n",
    "    [f'{c}_avg' for c in DAY_METRICS]\n",
    ")\n",
    "\n",
    "# Only the true disease flags (exclude plan/doctor/cost/cholesterol_check)\n",
    "DISEASE_FLAGS = [\n",
    "    'high_blood_pressure','high_cholesterol','diagnosed_diabetes',\n",
    "    'had_heart_attack','had_coronary_heart_disease','had_stroke',\n",
    "    'has_asthma','had_skin_cancer','had_other_cancer','has_copd',\n",
    "    'has_arthritis','has_depression','had_kidney_disease'\n",
    "]\n",
    "\n",
    "# Bucketing thresholds (simple & clear)\n",
    "HIGH_MIN   = 3          # High if total_disease >= 3\n",
    "MEDIUM_MIN = 1          # Medium if total_disease 1..2\n",
    "MEDIUM_MAX = 2\n",
    "LOW_MAX    = 0          # Low if total_disease == 0\n",
    "\n",
    "# Rounding config\n",
    "DECIMALS = 2            # round aggregates to 2 decimals\n",
    "\n",
    "# ---------------------\n",
    "# DB helpers\n",
    "# ---------------------\n",
    "def get_engine(uri: str):\n",
    "    return create_engine(uri)\n",
    "\n",
    "def ensure_schemas(engine):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {SILVER_SCHEMA};\"))\n",
    "        conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {GOLD_SCHEMA};\"))\n",
    "\n",
    "def table_rowcount(engine, schema: str, table: str) -> int:\n",
    "    with engine.connect() as conn:\n",
    "        return conn.exec_driver_sql(f\"SELECT COUNT(*) FROM {schema}.{table};\").scalar()\n",
    "\n",
    "def get_table_columns(engine, schema: str, table: str):\n",
    "    # Fetch one row to get column names\n",
    "    df = pd.read_sql_query(text(f\"SELECT * FROM {schema}.{table} LIMIT 1\"), con=engine)\n",
    "    return df.columns.tolist()\n",
    "\n",
    "# ---------------------\n",
    "# Sampling\n",
    "# ---------------------\n",
    "def fetch_random_sample(engine, sample_size=SAMPLE_SIZE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fast sampler for large tables:\n",
    "    - Uses LIMIT + random OFFSET (pseudo-random, very fast).\n",
    "    - Avoids ORDER BY RANDOM() which is slow on millions of rows.\n",
    "    \"\"\"\n",
    "    total_df = pd.read_sql_query(\n",
    "        sql=text(f\"SELECT COUNT(*) AS c FROM {SILVER_SCHEMA}.{SILVER_TABLE}\"),\n",
    "        con=engine\n",
    "    )\n",
    "    \n",
    "    total = int(total_df['c'][0])\n",
    "    if total == 0:\n",
    "        raise RuntimeError(f\"{SILVER_SCHEMA}.{SILVER_TABLE} is empty.\")\n",
    "\n",
    "    offset = max(0, random.randint(0, max(0, total - sample_size)))\n",
    "    query = f\"\"\"\n",
    "        SELECT {', '.join(GOLD_COLS)}\n",
    "        FROM {SILVER_SCHEMA}.{SILVER_TABLE}\n",
    "        OFFSET {offset}\n",
    "        LIMIT {sample_size}\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql=text(query), conn =engine)\n",
    "\n",
    "    # ‚úÖ Enrich before writing to gold\n",
    "    df = enrich_gold_presentation(df)\n",
    "    return df\n",
    "\n",
    "# ---------------------\n",
    "# Enrich sample with basic burden columns\n",
    "# ---------------------\n",
    "def enrich_gold_presentation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds row-level columns to the same gold1.presentation table:\n",
    "      - total_disease\n",
    "      - has_any_disease\n",
    "      - multimorbidity_flag\n",
    "      - severe_multimorbidity_flag\n",
    "      - disease_rank (Low/Medium/High)\n",
    "      - risk_bucket (friendly labels)\n",
    "    \"\"\"\n",
    "    # Coerce disease flags safely\n",
    "    for c in DISEASE_FLAGS:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        else:\n",
    "            raise KeyError(f\"Missing expected disease flag: {c}\")\n",
    "\n",
    "    # Total diseases per respondent (sum of 1s across disease flags)\n",
    "    total = (df[DISEASE_FLAGS] == YES_VALUE).sum(axis=1)\n",
    "    df['total_disease'] = total.astype('int16')\n",
    "\n",
    "    # Simple binary helpers\n",
    "    df['has_any_disease']            = (df['total_disease'] > 0).astype('int8')\n",
    "    df['multimorbidity_flag']        = (df['total_disease'] >= 2).astype('int8')\n",
    "    df['severe_multimorbidity_flag'] = (df['total_disease'] >= 3).astype('int8')\n",
    "\n",
    "    # Rank buckets\n",
    "    def _rank(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        if x >= HIGH_MIN: return \"High\"\n",
    "        if MEDIUM_MIN <= x <= MEDIUM_MAX: return \"Medium\"\n",
    "        if x <= LOW_MAX: return \"Low\"\n",
    "        return \"Medium\"\n",
    "\n",
    "    df['disease_rank'] = df['total_disease'].apply(_rank).astype('string')\n",
    "\n",
    "    # Friendly bucket label\n",
    "    def _bucket(x):\n",
    "        if x == 0: return \"No disease\"\n",
    "        if x == 1: return \"1 disease\"\n",
    "        if x == 2: return \"2 diseases\"\n",
    "        return \"‚â•3 diseases\"\n",
    "\n",
    "    df['risk_bucket'] = df['total_disease'].apply(_bucket).astype('string')\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------------\n",
    "# Writing sample to Gold\n",
    "# ---------------------\n",
    "def write_sample_to_gold(engine, df: pd.DataFrame) -> int:\n",
    "    # Ensure column order & presence\n",
    "    existing = [c for c in GOLD_COLS if c in df.columns]\n",
    "    # Include the new columns too when writing\n",
    "    extra_cols = ['total_disease','has_any_disease','multimorbidity_flag',\n",
    "                  'severe_multimorbidity_flag','disease_rank','risk_bucket']\n",
    "    for c in extra_cols:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"Missing expected enriched column: {c}\")\n",
    "\n",
    "    df = df[existing + extra_cols]\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        df.to_sql(\n",
    "            name=GOLD_TABLE,\n",
    "            con=conn,\n",
    "            schema=GOLD_SCHEMA,\n",
    "            if_exists='replace',   # overwrite each run (deterministic)\n",
    "            index=False,\n",
    "            method='multi',\n",
    "            chunksize=50_000\n",
    "        )\n",
    "    return len(df)\n",
    "\n",
    "# ---------------------\n",
    "# Aggregation helpers\n",
    "# ---------------------\n",
    "def prevalence(series: pd.Series, yes_value=YES_VALUE):\n",
    "    \"\"\"Share of YES among non-null values.\"\"\"\n",
    "    s = pd.to_numeric(series, errors='coerce').dropna()\n",
    "    return (s == yes_value).mean() if len(s) else np.nan\n",
    "\n",
    "def align_columns(df: pd.DataFrame, target_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"Ensure df has all target columns (add missing as NaN) and reorder.\"\"\"\n",
    "    for c in target_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    return df[target_cols]\n",
    "\n",
    "def month_alignment_stats(df: pd.DataFrame):\n",
    "    \"\"\"Optional sanity: compare 'survey_month' and 'month' fields.\"\"\"\n",
    "    for col in ['survey_month', 'month', 'state']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df['month_mismatch'] = np.where(\n",
    "        df['survey_month'].notna() & df['month'].notna() & (df['survey_month'] != df['month']),\n",
    "        1, 0\n",
    "    )\n",
    "    by_state = (df.groupby('state')['month_mismatch']\n",
    "                  .mean()\n",
    "                  .reset_index()\n",
    "                  .rename(columns={'month_mismatch': 'month_mismatch_rate'}))\n",
    "    overall = df['month_mismatch'].mean()\n",
    "    return overall, by_state\n",
    "\n",
    "def round_agg_for_presentation(df: pd.DataFrame, decimals=2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Round only presentation KPIs in aggregates:\n",
    "      - *_prev, *_avg, *_null_pct ‚Üí round to 2 decimals\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if (\n",
    "            col.endswith('_prev') or\n",
    "            col.endswith('_avg') or\n",
    "            col.endswith('_null_pct')\n",
    "        ):\n",
    "            if pd.api.types.is_float_dtype(df[col]):\n",
    "                df[col] = df[col].round(decimals)\n",
    "    return df\n",
    "\n",
    "def dtype_numeric_2dp(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build dtype map: ints stay ints; floats become NUMERIC(10,2) for clean storage.\n",
    "    \"\"\"\n",
    "    dtypes = {}\n",
    "    for col in df.columns:\n",
    "        s = df[col]\n",
    "        if pd.api.types.is_integer_dtype(s):\n",
    "            dtypes[col] = Integer()\n",
    "        elif pd.api.types.is_float_dtype(s):\n",
    "            dtypes[col] = Numeric(10, 2)\n",
    "        elif pd.api.types.is_string_dtype(s):\n",
    "            dtypes[col] = String()\n",
    "        # leave bool/datetime to inference\n",
    "    return dtypes\n",
    "\n",
    "# ---------------------\n",
    "# BUILD AGGREGATIONS\n",
    "# ---------------------\n",
    "def build_profiles(df: pd.DataFrame):\n",
    "    \"\"\"Build overall null profiles, and aggregations by state and by (state, month).\"\"\"\n",
    "    # Null % overall (sample)\n",
    "    null_pct_overall = (df.isnull().mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "    # Coerce numeric for grouping columns + metrics\n",
    "    for col in INDICATORS + DAY_METRICS + ['state', 'survey_month', 'month', 'year']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # --- By state ---\n",
    "    agg_dict_state = {}\n",
    "    for col in INDICATORS:\n",
    "        agg_dict_state[col + '_prev'] = (col, prevalence)\n",
    "    for col in DAY_METRICS:\n",
    "        agg_dict_state[col + '_avg'] = (col, 'mean')\n",
    "\n",
    "    agg_frame_state = df.groupby('state').agg(\n",
    "        rows=('state', 'size'),\n",
    "        **agg_dict_state\n",
    "    ).reset_index()\n",
    "\n",
    "    # Attach null% per column per state\n",
    "    for col in INDICATORS + DAY_METRICS:\n",
    "        s_null = (\n",
    "            df.groupby('state')[col]\n",
    "              .apply(lambda s: s.isna().mean() * 100)\n",
    "              .reset_index()\n",
    "              .rename(columns={col: f'{col}_null_pct'})\n",
    "        )\n",
    "        agg_frame_state = agg_frame_state.merge(s_null, on='state', how='left')\n",
    "\n",
    "    # Align to target column order (ensures DDL match)\n",
    "    agg_frame_state = align_columns(agg_frame_state, STATE_AGG_COLS)\n",
    "    # ‚úÖ Round presentation KPIs to 2 decimals\n",
    "    agg_frame_state = round_agg_for_presentation(agg_frame_state, decimals=DECIMALS)\n",
    "\n",
    "    # --- By (state, month) ---\n",
    "    agg_dict_state_month = {}\n",
    "    for col in INDICATORS:\n",
    "        agg_dict_state_month[col + '_prev'] = (col, prevalence)\n",
    "    for col in DAY_METRICS:\n",
    "        agg_dict_state_month[col + '_avg'] = (col, 'mean')\n",
    "\n",
    "    agg_frame_state_month = df.groupby(['state', 'month']).agg(\n",
    "        rows=('state', 'size'),\n",
    "        **agg_dict_state_month\n",
    "    ).reset_index()\n",
    "\n",
    "    # Align to target column order & round\n",
    "    agg_frame_state_month = align_columns(agg_frame_state_month, STATE_MONTH_AGG_COLS)\n",
    "    agg_frame_state_month = round_agg_for_presentation(agg_frame_state_month, decimals=DECIMALS)\n",
    "\n",
    "    return null_pct_overall, agg_frame_state, agg_frame_state_month\n",
    "\n",
    "# ---------------------\n",
    "# CREATE GOLD TABLES (DDL)\n",
    "# ---------------------\n",
    "def ensure_gold_agg_tables(engine):\n",
    "    \"\"\"\n",
    "    Create aggregate tables with NUMERIC(10,2) for presentation columns to ensure\n",
    "    clean display (no long floating-point tails).\n",
    "    \"\"\"\n",
    "    # DDL for metrics_by_state\n",
    "    ddl_state = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {GOLD_SCHEMA}.{GOLD_AGG_STATE} (\n",
    "        state int,\n",
    "        rows bigint,\n",
    "        has_health_plan_prev      NUMERIC(10,2),\n",
    "        has_personal_doctor_prev  NUMERIC(10,2),\n",
    "        medical_cost_issue_prev   NUMERIC(10,2),\n",
    "        high_blood_pressure_prev  NUMERIC(10,2),\n",
    "        high_cholesterol_prev     NUMERIC(10,2),\n",
    "        cholesterol_check_prev    NUMERIC(10,2),\n",
    "        diagnosed_diabetes_prev   NUMERIC(10,2),\n",
    "        had_heart_attack_prev     NUMERIC(10,2),\n",
    "        had_coronary_heart_disease_prev NUMERIC(10,2),\n",
    "        had_stroke_prev           NUMERIC(10,2),\n",
    "        has_asthma_prev           NUMERIC(10,2),\n",
    "        had_skin_cancer_prev      NUMERIC(10,2),\n",
    "        had_other_cancer_prev     NUMERIC(10,2),\n",
    "        has_copd_prev             NUMERIC(10,2),\n",
    "        has_arthritis_prev        NUMERIC(10,2),\n",
    "        has_depression_prev       NUMERIC(10,2),\n",
    "        had_kidney_disease_prev   NUMERIC(10,2),\n",
    "        physical_health_days_avg  NUMERIC(10,2),\n",
    "        mental_health_days_avg    NUMERIC(10,2),\n",
    "        poor_health_days_avg      NUMERIC(10,2),\n",
    "        has_health_plan_null_pct      NUMERIC(10,2),\n",
    "        has_personal_doctor_null_pct  NUMERIC(10,2),\n",
    "        medical_cost_issue_null_pct   NUMERIC(10,2),\n",
    "        high_blood_pressure_null_pct  NUMERIC(10,2),\n",
    "        high_cholesterol_null_pct     NUMERIC(10,2),\n",
    "        cholesterol_check_null_pct    NUMERIC(10,2),\n",
    "        diagnosed_diabetes_null_pct   NUMERIC(10,2),\n",
    "        had_heart_attack_null_pct     NUMERIC(10,2),\n",
    "        had_coronary_heart_disease_null_pct NUMERIC(10,2),\n",
    "        had_stroke_null_pct           NUMERIC(10,2),\n",
    "        has_asthma_null_pct           NUMERIC(10,2),\n",
    "        had_skin_cancer_null_pct      NUMERIC(10,2),\n",
    "        had_other_cancer_null_pct     NUMERIC(10,2),\n",
    "        has_copd_null_pct             NUMERIC(10,2),\n",
    "        has_arthritis_null_pct        NUMERIC(10,2),\n",
    "        has_depression_null_pct       NUMERIC(10,2),\n",
    "        had_kidney_disease_null_pct   NUMERIC(10,2),\n",
    "        physical_health_days_null_pct NUMERIC(10,2),\n",
    "        mental_health_days_null_pct   NUMERIC(10,2),\n",
    "        poor_health_days_null_pct     NUMERIC(10,2)\n",
    "    );\n",
    "    \"\"\"\n",
    "    # DDL for metrics_by_state_month\n",
    "    ddl_state_month = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {GOLD_SCHEMA}.{GOLD_AGG_STATE_MONTH} (\n",
    "        state int,\n",
    "        month int,\n",
    "        rows bigint,\n",
    "        has_health_plan_prev      NUMERIC(10,2),\n",
    "        has_personal_doctor_prev  NUMERIC(10,2),\n",
    "        medical_cost_issue_prev   NUMERIC(10,2),\n",
    "        high_blood_pressure_prev  NUMERIC(10,2),\n",
    "        high_cholesterol_prev     NUMERIC(10,2),\n",
    "        cholesterol_check_prev    NUMERIC(10,2),\n",
    "        diagnosed_diabetes_prev   NUMERIC(10,2),\n",
    "        had_heart_attack_prev     NUMERIC(10,2),\n",
    "        had_coronary_heart_disease_prev NUMERIC(10,2),\n",
    "        had_stroke_prev           NUMERIC(10,2),\n",
    "        has_asthma_prev           NUMERIC(10,2),\n",
    "        had_skin_cancer_prev      NUMERIC(10,2),\n",
    "        had_other_cancer_prev     NUMERIC(10,2),\n",
    "        has_copd_prev             NUMERIC(10,2),\n",
    "        has_arthritis_prev        NUMERIC(10,2),\n",
    "        has_depression_prev       NUMERIC(10,2),\n",
    "        had_kidney_disease_prev   NUMERIC(10,2),\n",
    "        physical_health_days_avg  NUMERIC(10,2),\n",
    "        mental_health_days_avg    NUMERIC(10,2),\n",
    "        poor_health_days_avg      NUMERIC(10,2)\n",
    "    );\n",
    "    \"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(ddl_state))\n",
    "        conn.execute(text(ddl_state_month))\n",
    "\n",
    "def write_aggs_to_gold(engine, agg_state: pd.DataFrame, agg_state_month: pd.DataFrame):\n",
    "    ensure_gold_agg_tables(engine)\n",
    "    with engine.begin() as conn:\n",
    "        # Truncate existing data and append (keeps DDL intact)\n",
    "        conn.execute(text(f\"TRUNCATE TABLE {GOLD_SCHEMA}.{GOLD_AGG_STATE};\"))\n",
    "        conn.execute(text(f\"TRUNCATE TABLE {GOLD_SCHEMA}.{GOLD_AGG_STATE_MONTH};\"))\n",
    "\n",
    "        # Append with explicit dtype mapping (floats -> NUMERIC(10,2))\n",
    "        agg_state.to_sql(\n",
    "            name=GOLD_AGG_STATE, schema=GOLD_SCHEMA, con=conn,\n",
    "            if_exists='append', index=False, method='multi', chunksize=50_000,\n",
    "            dtype=dtype_numeric_2dp(agg_state)\n",
    "        )\n",
    "        agg_state_month.to_sql(\n",
    "            name=GOLD_AGG_STATE_MONTH, schema=GOLD_SCHEMA, con=conn,\n",
    "            if_exists='append', index=False, method='multi', chunksize=50_000,\n",
    "            dtype=dtype_numeric_2dp(agg_state_month)\n",
    "        )\n",
    "\n",
    "def create_gold_indexes(engine):\n",
    "    stmts = [\n",
    "        f\"CREATE INDEX IF NOT EXISTS ix_{GOLD_SCHEMA}_{GOLD_TABLE}_state ON {GOLD_SCHEMA}.{GOLD_TABLE}(state);\",\n",
    "        f\"CREATE INDEX IF NOT EXISTS ix_{GOLD_SCHEMA}_{GOLD_TABLE}_survey_month ON {GOLD_SCHEMA}.{GOLD_TABLE}(survey_month);\",\n",
    "        f\"CREATE INDEX IF NOT EXISTS ix_{GOLD_SCHEMA}_{GOLD_AGG_STATE}_state ON {GOLD_SCHEMA}.{GOLD_AGG_STATE}(state);\",\n",
    "        f\"CREATE INDEX IF NOT EXISTS ix_{GOLD_SCHEMA}_{GOLD_AGG_STATE_MONTH}_state_month ON {GOLD_SCHEMA}.{GOLD_AGG_STATE_MONTH}(state, month);\",\n",
    "    ]\n",
    "    with engine.begin() as conn:\n",
    "        for s in stmts:\n",
    "            conn.execute(text(s))\n",
    "\n",
    "# ---------------------\n",
    "# MAIN orchestration\n",
    "# ---------------------\n",
    "def run_gold_pipeline(engine):\n",
    "    try:\n",
    "        ensure_schemas(engine)\n",
    "\n",
    "        # Diagnostics\n",
    "        with engine.connect() as conn:\n",
    "            version = conn.exec_driver_sql(\"SELECT version();\").scalar()\n",
    "            print(\"PostgreSQL version:\", version)\n",
    "        silver_rows = table_rowcount(engine, SILVER_SCHEMA, SILVER_TABLE)\n",
    "        print(f\"Silver table rowcount: {silver_rows:,}\")\n",
    "\n",
    "        # 1) Sample 200k rows\n",
    "        print(\"\\nüîπ Sampling 200,000 rows from silver1.cleaned ...\")\n",
    "        df = fetch_random_sample(engine, SAMPLE_SIZE)\n",
    "        print(f\"‚úÖ Sample fetched: {len(df):,} rows\")\n",
    "\n",
    "        if df.empty:\n",
    "            raise RuntimeError(\"Sample is empty ‚Äî check table name/columns or sampler.\")\n",
    "\n",
    "        # 2) Write sample to Gold (with enriched columns)\n",
    "        print(\"\\nüîπ Writing sampled rows to gold1.presentation ...\")\n",
    "        written = write_sample_to_gold(engine, df)\n",
    "        print(f\"‚úÖ Written to gold1.presentation: {written:,} rows\")\n",
    "\n",
    "        # 3) Build analytics\n",
    "        print(\"\\nüîπ Building analytics (null profiles, prevalence, averages) ...\")\n",
    "        null_pct_overall, agg_state, agg_state_month = build_profiles(df)\n",
    "        print(f\"‚úÖ State metrics rows: {len(agg_state)} | State-month metrics rows: {len(agg_state_month)}\")\n",
    "\n",
    "        # 4) Write aggregates\n",
    "        print(\"\\nüîπ Writing aggregated outputs to Gold tables ...\")\n",
    "        write_aggs_to_gold(engine, agg_state, agg_state_month)\n",
    "        create_gold_indexes(engine)\n",
    "        print(\"‚úÖ Gold layer analytics written and indexed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"‚ùå ERROR in pipeline:\", e)\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # üîê Set your actual URI below:\n",
    "    ENGINE_URI = \"postgresql+psycopg2://postgres:123456@localhost:5432/Project1\"\n",
    "    engine = get_engine(ENGINE_URI)\n",
    "    run_gold_pipeline(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6f3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
